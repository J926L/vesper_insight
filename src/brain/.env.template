# RTX 3060 (6GB) AI Support Config
CUDA_VISIBLE_DEVICES=0

# Limit VRAM fragmentation
PYTORCH_ALLOC_CONF=expandable_segments:True

# Memory management for 6GB VRAM
# Ensure models are loaded in 4-bit or 8-bit quantization if possible.
MAX_VRAM_GB=6
